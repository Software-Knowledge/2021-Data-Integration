Hw2-第二次作业说明
---

1. 路线一不建议做，但是也会根据工作量进行评分，自由扩展功能
2. 路线二：
   1. 作业一：批处理集成 + 实时数据集成，批处理数据集成，找到一个简单的规律
   2. 作业二：
      1. 电商平台，提供比较丰富的数据源
      2. 整个业务框架，完成数据集成的部分
      3. 技术框架，并搭建(大部分工具安装即可)
      4. 项目提交：PDF
      5. 路径二提供DEMO
      6. 成本csv取消掉，log用流(消息中间件)的方式来推送，提交ip + port端口
      7. sqoop拉取到本地需要持久化。
      8. 从4月10日开始推，然后拉取数据，只需要拉取下来，然后尝试发现规律即可
      9. 下下周的时候做交流：包括拉取数据、数据分析找规律过程
      10. 数据
          1. 表数据已经发布
          2. 流式数据明天开始发布
      11. 核心是拿到数据，数据存储和数据分析
   3. 作业三：有问题直接问助教，6月份提交，然后要做matplotlib的部分
   4. 小作业：第一次小作业时将数据文件导入，然后做一个简单的数据分析，主要运行即可
3. 路线三：金融知识图谱的构建与应用(4月中旬至少有一次)

# 1. 各小组分享和交流
1. ip地址不一样，重新配置(调为一个网段)：将nat修改为桥接
2. hive没开启10000端口监听

## 1.1. 静态数据分析
1. 思路
   1. 2019年基于区段的机器人流量的分段分析(查一些文献来完成)
   2. 捆绑销售(KNN分析特征相近、aprioir算法)
   3. 用户画像
2. 分析点：
   1. 某一个商品在某个时间段大量下单
   2. 某一个时间段有大量商品下单(问题是不是在一个购物车内)
   3. 购买最多
   4. 商品复购率、热门产品
3. 绘图：
   1. timestamp和item_id绘图，一个颜色是一个user_id(一个timestamp下单很多，但是可能是一个购物车内的)
4. 其他技术点：
   1. Java:AtomicReference
   2. Flink:进行实时数据分析
5. 问题
   1. 流数据USER_ID都是6位，静态数据里面USER_ID都是7位需要检查
   2. 流数据的时间是实际时间，数据库表是时间戳
   3. 静态数据有脏数据

## 1.2. 流数据分析
1. 撞库机器人：
   1. 中位数不容易受到异常值影响，取中位数作为真人用户的正常频率
   2. 单一IP登录的成功率比整体IP登录的成功率低
2. 抢单机器人：刷单频率
3. 刷单机器人：
4. 爬虫机器人：

## 1.3. 数据可视化